{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaldiio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95937e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaldiio\n",
    "import pandas as pd\n",
    "\n",
    "temp = []\n",
    "temp1 = []\n",
    "dictlist = []\n",
    "dictlist1 = []\n",
    "d = kaldiio.load_ark('StressDat_trillv3.ark')  # d is a generator object\n",
    "for key, numpy_array in d:\n",
    "    temp = key\n",
    "    temp1 = numpy_array\n",
    "    dictlist.append(temp)\n",
    "    dictlist1.append(temp1)\n",
    "df = pd.DataFrame(list(zip(dictlist, dictlist1)),\n",
    "               columns =['FILE', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "audio_dataset_path=r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat'\n",
    "header_list = [\"FILE\", \"Annotators\", \"SCORE\"]\n",
    "metadata=pd.read_csv(r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat\\StressDat-anotacia-29spk_v1_normalize_all_scores.txt',sep=\"\\t\",names=header_list)\n",
    "conditions = [\n",
    "    (metadata['SCORE'] <= 20),\n",
    "    (metadata['SCORE'] > 20) & (metadata['SCORE'] <= 40),\n",
    "    (metadata['SCORE'] > 40)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['low', 'med', 'high']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "metadata['SCALE'] = np.select(conditions, values)\n",
    "# display updated DataFrame\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=pd.read_csv(r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat\\modified.csv',sep=\"\\t\")\n",
    "\n",
    "metadata.rename(columns={'V1': 'FILE', 'V2': 'Annotators', 'V3': 'SCORE'}, inplace=True)\n",
    "# display updated DataFrame\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0af94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X1= pd.merge(metadata, df, on='FILE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df = X1[[\"SCALE\",\"features\"]]\n",
    "extracted_features_df.columns=['class_label','feature']\n",
    "extracted_features_df.to_pickle(\"newtrill_features512_1D.pkl\",protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c14226",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df\n",
    "extracted_features_df.to_pickle(\"trill_features51_1D.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbb5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "extracted_features_df = pd.read_pickle(r\"C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\Pickle\\newtrill_features512_1D.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d504d873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medium</td>\n",
       "      <td>[0.0161692, 0.0390885, -0.0046351, -0.0020949,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>[0.0168201, -0.0282048, 0.039324, -0.0603364, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medium</td>\n",
       "      <td>[-0.0064451, -0.0812835, -0.0166688, -0.015342...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High</td>\n",
       "      <td>[0.01027, 0.0524941, -0.0217838, 0.0042399, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medium</td>\n",
       "      <td>[-0.055569, 0.0133011, 0.034179, -0.0342438, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12784</th>\n",
       "      <td>Low</td>\n",
       "      <td>[-0.0468368, -0.0192087, -0.01929, -0.0296526,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>Low</td>\n",
       "      <td>[-0.0222033, -0.0192389, 0.0137476, 0.0044978,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>Medium</td>\n",
       "      <td>[0.0566024, -0.0882919, 0.0271667, -0.0018073,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>Low</td>\n",
       "      <td>[-0.0077951, -0.0332874, 0.0201664, 0.0020362,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>High</td>\n",
       "      <td>[-0.0521281, -0.038472, -0.0078298, -0.030251,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12789 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class_label                                            feature\n",
       "0          Medium  [0.0161692, 0.0390885, -0.0046351, -0.0020949,...\n",
       "1          Medium  [0.0168201, -0.0282048, 0.039324, -0.0603364, ...\n",
       "2          Medium  [-0.0064451, -0.0812835, -0.0166688, -0.015342...\n",
       "3            High  [0.01027, 0.0524941, -0.0217838, 0.0042399, -0...\n",
       "4          Medium  [-0.055569, 0.0133011, 0.034179, -0.0342438, -...\n",
       "...           ...                                                ...\n",
       "12784         Low  [-0.0468368, -0.0192087, -0.01929, -0.0296526,...\n",
       "12785         Low  [-0.0222033, -0.0192389, 0.0137476, 0.0044978,...\n",
       "12786      Medium  [0.0566024, -0.0882919, 0.0271667, -0.0018073,...\n",
       "12787         Low  [-0.0077951, -0.0332874, 0.0201664, 0.0020362,...\n",
       "12788        High  [-0.0521281, -0.038472, -0.0078298, -0.030251,...\n",
       "\n",
       "[12789 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "### Split the dataset into independent and dependent dataset\n",
    "\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class_label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bca221",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa86300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=np.array(extracted_features_df['class'].tolist())\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2aa966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f037b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10759145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(512,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14962da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy=model.evaluate(X_train,y_train,verbose=0)\n",
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(train_accuracy[1])\n",
    "print(test_accuracy[1])\n",
    "#New Trill vectors\n",
    "#0.9394975900650024\n",
    "#0.808444082736969\n",
    "\n",
    "\n",
    "#Trill vectors\n",
    "#0.9453712105751038\n",
    "#0.8154506683349609\n",
    "\n",
    "\n",
    "#Xvectors\n",
    "#0.8511364459991455\n",
    "#0.7943815588951111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65038f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df['class_label']\n",
    "extracted_features_df['class_label'].replace({\"Medium\": 1, \"High\": 2,\"Low\":0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f207bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class_label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff9f7916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645c1935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed5dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=np.array(extracted_features_df['class_label'].tolist())\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5478931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b160c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10231, 3) (2558, 3) (10231, 512, 1) (2558, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "### Train Test Split\n",
    "num_classes = 3;\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "Y_train_ann_cnn = y_train\n",
    "Y_test_ann_cnn = y_test\n",
    "\n",
    "print(Y_train_ann_cnn.shape,Y_test_ann_cnn.shape,X_train_cnn.shape,X_test_cnn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97f0325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Convolution1D, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Convolution1D, MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Convolution1D, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Convolution1D, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "from kerastuner import RandomSearch\n",
    "import keras_tuner\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20f10bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 512, 16)           48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 256, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,116,499\n",
      "Trainable params: 1,116,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, input_shape=X_train_cnn.shape[1:], kernel_size=2, activation='relu',padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu',padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Conv1D(filters=64, kernel_size=2, activation='relu',padding='same'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Conv1D(filters=128, kernel_size=2, activation='relu',padding='same'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3215721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5728b26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 0.9149 - accuracy: 0.5267 - val_loss: 0.5478 - val_accuracy: 0.7553\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54781, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 0.5882 - accuracy: 0.7361 - val_loss: 0.5189 - val_accuracy: 0.7694\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54781 to 0.51890, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.5490 - accuracy: 0.7538 - val_loss: 0.4924 - val_accuracy: 0.7823\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51890 to 0.49235, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 4s 14ms/step - loss: 0.5348 - accuracy: 0.7601 - val_loss: 0.4891 - val_accuracy: 0.7834\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49235 to 0.48909, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 4s 14ms/step - loss: 0.5198 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.7916\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48909 to 0.48845, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.5089 - accuracy: 0.7732 - val_loss: 0.4776 - val_accuracy: 0.7901\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48845 to 0.47760, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.5070 - accuracy: 0.7743 - val_loss: 0.4707 - val_accuracy: 0.7916\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47760 to 0.47074, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4883 - accuracy: 0.7823 - val_loss: 0.4756 - val_accuracy: 0.7885\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.47074\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4659 - accuracy: 0.7947 - val_loss: 0.4928 - val_accuracy: 0.7862\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.47074\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4620 - accuracy: 0.7963 - val_loss: 0.4722 - val_accuracy: 0.7952\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.47074\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4554 - accuracy: 0.7967 - val_loss: 0.4572 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.47074 to 0.45719, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4434 - accuracy: 0.8056 - val_loss: 0.4616 - val_accuracy: 0.7991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45719\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4504 - accuracy: 0.8014 - val_loss: 0.4602 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45719\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4299 - accuracy: 0.8106 - val_loss: 0.4701 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45719\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4134 - accuracy: 0.8213 - val_loss: 0.4534 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.45719 to 0.45341, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4040 - accuracy: 0.8187 - val_loss: 0.4621 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45341\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4036 - accuracy: 0.8250 - val_loss: 0.4509 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.45341 to 0.45085, saving model to saved_models\\audio_classification54.hdf5\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.4069 - accuracy: 0.8240 - val_loss: 0.4572 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45085\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3986 - accuracy: 0.8271 - val_loss: 0.4611 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45085\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 6s 18ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.4564 - val_accuracy: 0.8041\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.45085\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3812 - accuracy: 0.8348 - val_loss: 0.4814 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.45085\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3739 - accuracy: 0.8344 - val_loss: 0.4644 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.45085\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 6s 17ms/step - loss: 0.3780 - accuracy: 0.8339 - val_loss: 0.4736 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.45085\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 6s 17ms/step - loss: 0.3644 - accuracy: 0.8370 - val_loss: 0.4753 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.45085\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3519 - accuracy: 0.8479 - val_loss: 0.4736 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.45085\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3606 - accuracy: 0.8448 - val_loss: 0.4893 - val_accuracy: 0.7995\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.45085\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3624 - accuracy: 0.8402 - val_loss: 0.4700 - val_accuracy: 0.7936\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.45085\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3614 - accuracy: 0.8403 - val_loss: 0.4731 - val_accuracy: 0.7998\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.45085\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3336 - accuracy: 0.8534 - val_loss: 0.4744 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.45085\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3455 - accuracy: 0.8461 - val_loss: 0.4970 - val_accuracy: 0.8073\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.45085\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3291 - accuracy: 0.8585 - val_loss: 0.4758 - val_accuracy: 0.8088\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.45085\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3348 - accuracy: 0.8525 - val_loss: 0.5117 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.45085\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3262 - accuracy: 0.8548 - val_loss: 0.4789 - val_accuracy: 0.8045\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.45085\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3291 - accuracy: 0.8559 - val_loss: 0.5042 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.45085\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3008 - accuracy: 0.8726 - val_loss: 0.4848 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.45085\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3123 - accuracy: 0.8642 - val_loss: 0.5095 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.45085\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3102 - accuracy: 0.8681 - val_loss: 0.5140 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.45085\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.3172 - accuracy: 0.8621 - val_loss: 0.4920 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.45085\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2886 - accuracy: 0.8752 - val_loss: 0.5017 - val_accuracy: 0.8006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_loss did not improve from 0.45085\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2915 - accuracy: 0.8736 - val_loss: 0.4881 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.45085\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2814 - accuracy: 0.8833 - val_loss: 0.5060 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.45085\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 6s 17ms/step - loss: 0.2881 - accuracy: 0.8770 - val_loss: 0.5028 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.45085\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2985 - accuracy: 0.8694 - val_loss: 0.5221 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.45085\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2934 - accuracy: 0.8737 - val_loss: 0.5274 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.45085\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2749 - accuracy: 0.8788 - val_loss: 0.5194 - val_accuracy: 0.8049\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.45085\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2640 - accuracy: 0.8876 - val_loss: 0.5418 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.45085\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2847 - accuracy: 0.8767 - val_loss: 0.5245 - val_accuracy: 0.7998\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.45085\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2722 - accuracy: 0.8790 - val_loss: 0.5321 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.45085\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2704 - accuracy: 0.8848 - val_loss: 0.5507 - val_accuracy: 0.7940\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.45085\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2719 - accuracy: 0.8861 - val_loss: 0.5570 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.45085\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 6s 18ms/step - loss: 0.2697 - accuracy: 0.8867 - val_loss: 0.5392 - val_accuracy: 0.8065\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.45085\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 6s 18ms/step - loss: 0.2713 - accuracy: 0.8831 - val_loss: 0.5435 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.45085\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 6s 19ms/step - loss: 0.2613 - accuracy: 0.8840 - val_loss: 0.5558 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.45085\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2628 - accuracy: 0.8820 - val_loss: 0.5368 - val_accuracy: 0.8073\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.45085\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2690 - accuracy: 0.8869 - val_loss: 0.5550 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.45085\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2422 - accuracy: 0.8957 - val_loss: 0.5675 - val_accuracy: 0.8006\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.45085\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2446 - accuracy: 0.8955 - val_loss: 0.5290 - val_accuracy: 0.8010\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.45085\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2392 - accuracy: 0.8940 - val_loss: 0.5293 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.45085\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2468 - accuracy: 0.8899 - val_loss: 0.5479 - val_accuracy: 0.8073\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.45085\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2352 - accuracy: 0.8977 - val_loss: 0.5679 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.45085\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2335 - accuracy: 0.8988 - val_loss: 0.5679 - val_accuracy: 0.8041\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.45085\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2279 - accuracy: 0.9026 - val_loss: 0.5728 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.45085\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2221 - accuracy: 0.9059 - val_loss: 0.5610 - val_accuracy: 0.8108\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.45085\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2507 - accuracy: 0.8902 - val_loss: 0.5858 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.45085\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2375 - accuracy: 0.8936 - val_loss: 0.5649 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.45085\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2363 - accuracy: 0.8953 - val_loss: 0.5798 - val_accuracy: 0.8049\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.45085\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2208 - accuracy: 0.9070 - val_loss: 0.5877 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.45085\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2034 - accuracy: 0.9131 - val_loss: 0.5674 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.45085\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2213 - accuracy: 0.9007 - val_loss: 0.5969 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.45085\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2234 - accuracy: 0.9036 - val_loss: 0.6215 - val_accuracy: 0.8057\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.45085\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2195 - accuracy: 0.9002 - val_loss: 0.5719 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.45085\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2045 - accuracy: 0.9110 - val_loss: 0.5793 - val_accuracy: 0.8088\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.45085\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2200 - accuracy: 0.9018 - val_loss: 0.5848 - val_accuracy: 0.8073\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.45085\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2034 - accuracy: 0.9083 - val_loss: 0.6405 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.45085\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2084 - accuracy: 0.9069 - val_loss: 0.5849 - val_accuracy: 0.8006\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.45085\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2045 - accuracy: 0.9128 - val_loss: 0.6123 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.45085\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2064 - accuracy: 0.9125 - val_loss: 0.6066 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.45085\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2180 - accuracy: 0.9095 - val_loss: 0.5865 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.45085\n",
      "Epoch 79/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2045 - accuracy: 0.9130 - val_loss: 0.6059 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.45085\n",
      "Epoch 80/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2019 - accuracy: 0.9153 - val_loss: 0.6151 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.45085\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2007 - accuracy: 0.9193 - val_loss: 0.6084 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.45085\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2018 - accuracy: 0.9101 - val_loss: 0.6038 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.45085\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.2015 - accuracy: 0.9122 - val_loss: 0.5788 - val_accuracy: 0.7975\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.45085\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1980 - accuracy: 0.9181 - val_loss: 0.6400 - val_accuracy: 0.7995\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.45085\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1923 - accuracy: 0.9171 - val_loss: 0.5990 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.45085\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1877 - accuracy: 0.9193 - val_loss: 0.6257 - val_accuracy: 0.8088\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.45085\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.2019 - accuracy: 0.9148 - val_loss: 0.5997 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.45085\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1876 - accuracy: 0.9200 - val_loss: 0.5918 - val_accuracy: 0.8065\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.45085\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1925 - accuracy: 0.9179 - val_loss: 0.6193 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.45085\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1985 - accuracy: 0.9176 - val_loss: 0.5941 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.45085\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1985 - accuracy: 0.9181 - val_loss: 0.6064 - val_accuracy: 0.8077\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.45085\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1845 - accuracy: 0.9231 - val_loss: 0.6293 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.45085\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1763 - accuracy: 0.9241 - val_loss: 0.6597 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.45085\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1885 - accuracy: 0.9170 - val_loss: 0.6522 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.45085\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1830 - accuracy: 0.9194 - val_loss: 0.6571 - val_accuracy: 0.7909\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.45085\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1800 - accuracy: 0.9266 - val_loss: 0.6553 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.45085\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1654 - accuracy: 0.9314 - val_loss: 0.6790 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.45085\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1632 - accuracy: 0.9276 - val_loss: 0.6185 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.45085\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 0.1864 - accuracy: 0.9204 - val_loss: 0.6409 - val_accuracy: 0.8010\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.45085\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 5s 17ms/step - loss: 0.1807 - accuracy: 0.9213 - val_loss: 0.6414 - val_accuracy: 0.8010\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.45085\n",
      "Training completed in time:  0:08:57.291047\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification54.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train_cnn, Y_train_ann_cnn, batch_size=num_batch_size, epochs=num_epochs, \n",
    "                   validation_data=(X_test_cnn, Y_test_ann_cnn), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "#94\n",
    "#80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy=model.evaluate(X_train_cnn,Y_train_ann_cnn,verbose=0)\n",
    "test_accuracy=model.evaluate(X_test_cnn,Y_test_ann_cnn,verbose=0)\n",
    "print(train_accuracy[1])\n",
    "print(test_accuracy[1])\n",
    "\n",
    "#XVectors\n",
    "#94\n",
    "#80\n",
    "\n",
    "#Trill vectors\n",
    "#0.959516167640686\n",
    "#0.8185719847679138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55640155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da4e2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import RandomSearch\n",
    "import keras_tuner\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d73988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  \n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv1D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [2,5]),\n",
    "        activation='relu',\n",
    "        input_shape=X_train_cnn.shape[1:]\n",
    "    ),\n",
    "    keras.layers.Conv1D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [2,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=256, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c364102",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=5,directory='output',project_name=\"Stress_clasification_mfcc12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "070268e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 31s]\n",
      "val_accuracy: 0.34636053442955017\n",
      "\n",
      "Best val_accuracy So Far: 0.7914020419120789\n",
      "Total elapsed time: 00h 02m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(X_train_cnn, Y_train_ann_cnn, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b44c9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23b6f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 511, 64)           192       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 510, 48)           6192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 24480)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 208)               5092048   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 627       \n",
      "=================================================================\n",
      "Total params: 5,099,059\n",
      "Trainable params: 5,099,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35140c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.2420 - accuracy: 0.8994 - val_loss: 0.5714 - val_accuracy: 0.7881\n",
      "Epoch 12/20\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.2043 - accuracy: 0.9167 - val_loss: 0.5532 - val_accuracy: 0.8037\n",
      "Epoch 13/20\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1865 - accuracy: 0.9241 - val_loss: 0.6214 - val_accuracy: 0.8125\n",
      "Epoch 14/20\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1546 - accuracy: 0.9383 - val_loss: 0.7025 - val_accuracy: 0.7920\n",
      "Epoch 15/20\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1212 - accuracy: 0.9521 - val_loss: 0.7329 - val_accuracy: 0.7900\n",
      "Epoch 16/20\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1069 - accuracy: 0.9607 - val_loss: 0.8279 - val_accuracy: 0.7881\n",
      "Epoch 17/20\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.0839 - accuracy: 0.9679 - val_loss: 0.9508 - val_accuracy: 0.7969\n",
      "Epoch 18/20\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.0700 - accuracy: 0.9737 - val_loss: 0.9841 - val_accuracy: 0.7881\n",
      "Epoch 19/20\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.0790 - accuracy: 0.9709 - val_loss: 1.0227 - val_accuracy: 0.7920\n",
      "Epoch 20/20\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.0427 - accuracy: 0.9845 - val_loss: 1.1791 - val_accuracy: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x246df532430>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_cnn, Y_train_ann_cnn, epochs=20, validation_split=0.1, initial_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60cd8912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9682338237762451\n",
      "0.7920250296592712\n"
     ]
    }
   ],
   "source": [
    "train_accuracy=model.evaluate(X_train_cnn,Y_train_ann_cnn,verbose=0)\n",
    "test_accuracy=model.evaluate(X_test_cnn,Y_test_ann_cnn,verbose=0)\n",
    "print(train_accuracy[1])\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0998146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Test Data: Full Classification Report \n",
      "[[774 120   0]\n",
      " [162 571 103]\n",
      " [  0 147 681]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       894\n",
      "           1       0.68      0.68      0.68       836\n",
      "           2       0.87      0.82      0.84       828\n",
      "\n",
      "    accuracy                           0.79      2558\n",
      "   macro avg       0.79      0.79      0.79      2558\n",
      "weighted avg       0.79      0.79      0.79      2558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"For Test Data: Full Classification Report \")\n",
    "Y_test = np.argmax(Y_test_ann_cnn, axis=1) # Convert one-hot to index\n",
    "y_pred = np.argmax(model.predict(X_test_cnn),axis=-1)\n",
    "matrix=confusion_matrix(Y_test,y_pred)\n",
    "print(matrix)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "407b0ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[774 120   0]\n",
      " [162 571 103]\n",
      " [  0 147 681]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-ffca020ff658>:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + labels)\n",
      "<ipython-input-36-ffca020ff658>:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + labels)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "labels=['High','Medium','Low',]\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "#New values\n",
    "#0.9054\n",
    "#0.8164\n",
    "#Xvectors\n",
    "#0.9515169262886047\n",
    "#0.8010144233703613\n",
    "\n",
    "#Trill vectors\n",
    "#0.914544939994812\n",
    "#0.8220834732055664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aabcc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61190841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm           = np.array([[774, 120,   0],\n",
    "                                                 [119, 571, 90],\n",
    "                                                 [0, 120, 681]]), \n",
    "                      normalize    = False,\n",
    "                      target_names = ['low', 'medium', 'high'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeeae30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
