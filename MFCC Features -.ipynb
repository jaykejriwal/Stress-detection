{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "\n",
    "conf_file =r'C:\\Opensmile\\opensmile-3.0-win-x64\\config\\mfcc\\MFCC12_0_D_A_new.conf' \n",
    "audio_path=r'D:\\wav\\*.wav'\n",
    "cvs_file=r'D:\\mfccfeatures.csv'\n",
    "path=r'C:\\Opensmile\\opensmile-3.0-win-x64\\bin'\n",
    "\n",
    "\n",
    "if os.path.exists(cvs_file):\n",
    "    print(Fore.BLUE+\"Deleteing old cvs file\") ,print(Style.RESET_ALL)\n",
    "    os.remove(cvs_file)\n",
    "\n",
    "\n",
    "for file in glob.iglob (audio_path):\n",
    "    print(Fore.MAGENTA+\"Exracting features from\", file),print(Style.RESET_ALL)\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(file)\n",
    "        audio.export(file,format=\"wav\")\n",
    "        cmd = path + \"./SMILExtract \" + \" -C \" + conf_file +\" -I \" + file +\" -O \" +cvs_file\n",
    "        os.system(cmd)\n",
    "    except : print (Fore.YELLOW+ file,\" is empty !\") ,print(Style.RESET_ALL) \n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a81f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install audb\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "import re\n",
    " \n",
    "# reading csv file\n",
    "df=pd.read_csv(r\"D:\\D drive\\Stress project\\mfccfeatures.csv\",sep=\";\")\n",
    "search = []    \n",
    "for values in df['name']:\n",
    "    search.append(re.search(r'\\w+\\.(wav)', values).group())\n",
    "\n",
    "df['name'] = search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r\"D:\\jaysrawfilefeatures.csv\")\n",
    "#skip\n",
    "#import pandas as pd\n",
    "#df=pd.read_csv(r\"D:\\D drive\\Stress project\\mfccfeatures.csv\",sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef82518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "#del df['frameIndex']\n",
    "#del df['frameTime']\n",
    "df_1 = df.copy()\n",
    "del df_1['frameIndex']\n",
    "del df_1['frameTime']\n",
    "df.drop(['frameIndex', 'frameTime', 'pcm_fftMag_mfcc_de[0]','pcm_fftMag_mfcc_de[1]','pcm_fftMag_mfcc_de[2]','pcm_fftMag_mfcc_de[3]','pcm_fftMag_mfcc_de[4]','pcm_fftMag_mfcc_de[5]','pcm_fftMag_mfcc_de[6]','pcm_fftMag_mfcc_de[7]',\n",
    "         'pcm_fftMag_mfcc_de[8]','pcm_fftMag_mfcc_de[9]','pcm_fftMag_mfcc_de[10]','pcm_fftMag_mfcc_de[11]',\n",
    "         'pcm_fftMag_mfcc_de[12]','pcm_fftMag_mfcc_de_de[0]','pcm_fftMag_mfcc_de_de[1]','pcm_fftMag_mfcc_de_de[2]',\n",
    "         'pcm_fftMag_mfcc_de_de[3]','pcm_fftMag_mfcc_de_de[4]','pcm_fftMag_mfcc_de_de[5]','pcm_fftMag_mfcc_de_de[6]',\n",
    "         'pcm_fftMag_mfcc_de_de[7]','pcm_fftMag_mfcc_de_de[8]','pcm_fftMag_mfcc_de_de[9]','pcm_fftMag_mfcc_de_de[10]',\n",
    "         'pcm_fftMag_mfcc_de_de[11]','pcm_fftMag_mfcc_de_de[12]'], axis=1, inplace=True)\n",
    "\n",
    "df2=df.groupby('name').agg(lambda x: list(x))\n",
    "df_2=df_1.groupby('name').agg(lambda x: list(x))\n",
    "#df2['features'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
    "\n",
    "#For 13 features\n",
    "df2['features']= df2.values.tolist()\n",
    "df2.reset_index(level=0, inplace=True)\n",
    "df2['name'] = df2['name'].str.replace('.wav','',regex=False)\n",
    "\n",
    "#For 39 features\n",
    "df_2['features']= df_2.values.tolist()\n",
    "df_2.reset_index(level=0, inplace=True)\n",
    "df_2['name'] = df_2['name'].str.replace('.wav','',regex=False)\n",
    "\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164edbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For merging columns\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01042273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['name','features']\n",
    "#df3 = df2.reindex(columns=header)\n",
    "df2.to_csv(r\"D:\\D drive\\Stress project\\mfccfeaturesready13.csv\", columns = header, index=False, sep=',')\n",
    "df_2.to_csv(r\"D:\\D drive\\Stress project\\mfccfeaturesready39.csv\", columns = header, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac54509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import re\n",
    "#df2=pd.read_csv(\"D:\\jaysfeaturesready.csv\",sep=\",\")\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ast import literal_eval\n",
    "#import pandas as pd\n",
    "\n",
    "# convert the column during import\n",
    "#df2 = pd.read_csv(\"D:\\jaysfeaturesready.csv\",sep=\",\", converters={'features': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1131d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['features'] = df2['features'].astype(float, errors = 'ignore')\n",
    "#df2.features[0]\n",
    "#header = ['name', 'features']\n",
    "#df2.to_csv(r\"D:\\mfccfeaturesready.csv\", columns = header, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c504e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "csv_data=pd.read_csv(r\"D:\\D drive\\Stress project\\mfccfeaturesready39.csv\", sep=',').values\n",
    "temp = []\n",
    "temp1 = []\n",
    "dictlist = []\n",
    "dictlist1 = []\n",
    "for audio in csv_data:\n",
    "#    audio_name=audio[0]\n",
    "#    print(audio_name)\n",
    "    features_string=audio[1]\n",
    "    #x1=np.array(features_string,dtype=float)\n",
    "    #x1=np.array([np.array(xi) for xi in features_string])\n",
    "    #x1=np.fromstring(features_string,dtype=float)\n",
    "    x1 = np.asarray(json.loads(features_string), dtype=np.float32)\n",
    "    x2 = np.mean(x1.T,axis=0)\n",
    "    temp = audio[0]\n",
    "    temp1 = x2\n",
    "    dictlist.append(temp)\n",
    "    dictlist1.append(temp1)\n",
    "df8 = pd.DataFrame(list(zip(dictlist, dictlist1)),\n",
    "               columns =['FILE', 'features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f3ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "max_pad=3376\n",
    "csv_data=pd.read_csv(r\"D:\\D drive\\Stress project\\mfccfeaturesready39.csv\", sep=',').values\n",
    "#csv_data=pd.read_csv('/home/jay_kejriwal/JAYBHAIcnn1.csv', sep=',').values\n",
    "temp = []\n",
    "temp1 = []\n",
    "dictlist = []\n",
    "dictlist1 = []\n",
    "for audio in csv_data:\n",
    "    features_string=audio[1]\n",
    "    x1 = np.asarray(json.loads(features_string), dtype=np.float32)\n",
    "    pad_width = max_pad - x1.shape[1]\n",
    "    x2 = np.pad(x1, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    temp = audio[0]\n",
    "    temp1 = x2\n",
    "    dictlist.append(temp)\n",
    "    dictlist1.append(temp1)\n",
    "df9 = pd.DataFrame(list(zip(dictlist, dictlist1)),columns =['FILE', 'features'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1380a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['features']=df2['features'].apply(np.array)\n",
    "#df2['features'] = df2['features'].apply(lambda x: x.astype('float'))\n",
    "#np.amax(df8['features'])\n",
    "df8.to_pickle(\"xxxxmfcc_features3376_39features_1D.pkl\",protocol=4)\n",
    "df9.to_pickle(\"xxxxmfcc_features3376_39features_2D.pkl\",protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcefb338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01a_10a_crisis_1_0265</td>\n",
       "      <td>[-3.7908356, -7.0894217, 5.152273, -23.238546,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s01a_10a_crisis_1_0266</td>\n",
       "      <td>[-3.455318, -7.5760384, 4.556436, -20.08264, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s01a_10a_crisis_1_0267</td>\n",
       "      <td>[-5.5255575, -10.008731, 6.2429314, -18.98753,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s01a_10a_crisis_1_0268</td>\n",
       "      <td>[-6.8184366, -6.213224, 6.330089, -17.130997, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s01a_10a_crisis_1_0269</td>\n",
       "      <td>[-8.12206, -7.660973, 8.351526, -20.514729, -8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13590</th>\n",
       "      <td>s29h_9c_crisis_3_0299</td>\n",
       "      <td>[-13.144755, -15.662556, -11.597349, -29.91652...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13591</th>\n",
       "      <td>s29h_9c_crisis_3_0300</td>\n",
       "      <td>[-14.921526, -9.364187, -2.5051222, -36.134514...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13592</th>\n",
       "      <td>s29h_9c_crisis_3_0301</td>\n",
       "      <td>[-11.597138, -16.094143, -5.67251, -26.683786,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13593</th>\n",
       "      <td>s29h_9c_crisis_3_0302</td>\n",
       "      <td>[-13.233461, -8.922029, -5.4360127, -27.970457...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13594</th>\n",
       "      <td>s29h_9c_crisis_3_0303</td>\n",
       "      <td>[-13.644776, -11.0979805, -6.2158856, -34.5662...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FILE  \\\n",
       "0      s01a_10a_crisis_1_0265   \n",
       "1      s01a_10a_crisis_1_0266   \n",
       "2      s01a_10a_crisis_1_0267   \n",
       "3      s01a_10a_crisis_1_0268   \n",
       "4      s01a_10a_crisis_1_0269   \n",
       "...                       ...   \n",
       "13590   s29h_9c_crisis_3_0299   \n",
       "13591   s29h_9c_crisis_3_0300   \n",
       "13592   s29h_9c_crisis_3_0301   \n",
       "13593   s29h_9c_crisis_3_0302   \n",
       "13594   s29h_9c_crisis_3_0303   \n",
       "\n",
       "                                                features  \n",
       "0      [-3.7908356, -7.0894217, 5.152273, -23.238546,...  \n",
       "1      [-3.455318, -7.5760384, 4.556436, -20.08264, -...  \n",
       "2      [-5.5255575, -10.008731, 6.2429314, -18.98753,...  \n",
       "3      [-6.8184366, -6.213224, 6.330089, -17.130997, ...  \n",
       "4      [-8.12206, -7.660973, 8.351526, -20.514729, -8...  \n",
       "...                                                  ...  \n",
       "13590  [-13.144755, -15.662556, -11.597349, -29.91652...  \n",
       "13591  [-14.921526, -9.364187, -2.5051222, -36.134514...  \n",
       "13592  [-11.597138, -16.094143, -5.67251, -26.683786,...  \n",
       "13593  [-13.233461, -8.922029, -5.4360127, -27.970457...  \n",
       "13594  [-13.644776, -11.0979805, -6.2158856, -34.5662...  \n",
       "\n",
       "[13595 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c60dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13595,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67fa275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01a_10a_crisis_1_0265</td>\n",
       "      <td>[[-13.86625, -18.47761, -14.26842, -12.02065, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s01a_10a_crisis_1_0266</td>\n",
       "      <td>[[-11.76748, -9.391284, -11.11567, -12.48359, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s01a_10a_crisis_1_0267</td>\n",
       "      <td>[[-7.418529, -12.53707, -15.07549, -12.09362, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s01a_10a_crisis_1_0268</td>\n",
       "      <td>[[-14.67007, -18.08006, -17.27793, -13.5949, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s01a_10a_crisis_1_0269</td>\n",
       "      <td>[[-11.4446, -14.79111, -14.48021, -14.97435, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13590</th>\n",
       "      <td>s29h_9c_crisis_3_0299</td>\n",
       "      <td>[[-31.29119, -34.56297, -36.48692, -37.79401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13591</th>\n",
       "      <td>s29h_9c_crisis_3_0300</td>\n",
       "      <td>[[-30.87927, -24.32855, -25.49979, -38.1184, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13592</th>\n",
       "      <td>s29h_9c_crisis_3_0301</td>\n",
       "      <td>[[-24.92476, -26.53362, -31.47085, -31.33543, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13593</th>\n",
       "      <td>s29h_9c_crisis_3_0302</td>\n",
       "      <td>[[-41.68302, -42.73156, -42.78324, -40.58368, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13594</th>\n",
       "      <td>s29h_9c_crisis_3_0303</td>\n",
       "      <td>[[-28.65054, -31.90983, -29.85241, -28.79337, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FILE  \\\n",
       "0      s01a_10a_crisis_1_0265   \n",
       "1      s01a_10a_crisis_1_0266   \n",
       "2      s01a_10a_crisis_1_0267   \n",
       "3      s01a_10a_crisis_1_0268   \n",
       "4      s01a_10a_crisis_1_0269   \n",
       "...                       ...   \n",
       "13590   s29h_9c_crisis_3_0299   \n",
       "13591   s29h_9c_crisis_3_0300   \n",
       "13592   s29h_9c_crisis_3_0301   \n",
       "13593   s29h_9c_crisis_3_0302   \n",
       "13594   s29h_9c_crisis_3_0303   \n",
       "\n",
       "                                                features  \n",
       "0      [[-13.86625, -18.47761, -14.26842, -12.02065, ...  \n",
       "1      [[-11.76748, -9.391284, -11.11567, -12.48359, ...  \n",
       "2      [[-7.418529, -12.53707, -15.07549, -12.09362, ...  \n",
       "3      [[-14.67007, -18.08006, -17.27793, -13.5949, -...  \n",
       "4      [[-11.4446, -14.79111, -14.48021, -14.97435, -...  \n",
       "...                                                  ...  \n",
       "13590  [[-31.29119, -34.56297, -36.48692, -37.79401, ...  \n",
       "13591  [[-30.87927, -24.32855, -25.49979, -38.1184, -...  \n",
       "13592  [[-24.92476, -26.53362, -31.47085, -31.33543, ...  \n",
       "13593  [[-41.68302, -42.73156, -42.78324, -40.58368, ...  \n",
       "13594  [[-28.65054, -31.90983, -29.85241, -28.79337, ...  \n",
       "\n",
       "[13595 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d118fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13595,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8893236a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>Annotators</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>SCALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s06h_10b_crisis_2_0315</td>\n",
       "      <td>2</td>\n",
       "      <td>28.846021</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s01a_6b_crisis_2_0170</td>\n",
       "      <td>2</td>\n",
       "      <td>32.322045</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s07n_8a_crisis_1_0244</td>\n",
       "      <td>1</td>\n",
       "      <td>17.074338</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s06h_9b_crisis_2_0284</td>\n",
       "      <td>2</td>\n",
       "      <td>43.659132</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s03a_9a_crisis_1_0274</td>\n",
       "      <td>1</td>\n",
       "      <td>27.351947</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FILE  Annotators      SCORE   SCALE\n",
       "0  s06h_10b_crisis_2_0315           2  28.846021  Medium\n",
       "1   s01a_6b_crisis_2_0170           2  32.322045  Medium\n",
       "2   s07n_8a_crisis_1_0244           1  17.074338  Medium\n",
       "3   s06h_9b_crisis_2_0284           2  43.659132    High\n",
       "4   s03a_9a_crisis_1_0274           1  27.351947  Medium"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=pd.read_csv(r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat\\modified.csv',sep=\"\\t\")\n",
    "\n",
    "metadata.rename(columns={'V1': 'FILE', 'V2': 'Annotators', 'V3': 'SCORE'}, inplace=True)\n",
    "# display updated DataFrame\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3eb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized score\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "audio_dataset_path=r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat'\n",
    "header_list = [\"FILE\", \"Annotators\", \"SCORE\"]\n",
    "metadata=pd.read_csv(r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat\\StressDat-anotacia-29spk_v1_normalize_all_scores.txt',sep=\"\\t\",names=header_list)\n",
    "conditions = [\n",
    "    (metadata['SCORE'] <= 20),\n",
    "    (metadata['SCORE'] > 20) & (metadata['SCORE'] <= 40),\n",
    "    (metadata['SCORE'] > 40)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['low', 'med', 'high']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "metadata['SCALE'] = np.select(conditions, values)\n",
    "# display updated DataFrame\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non normalized score\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "audio_dataset_path=r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat'\n",
    "#header_list = [\"FILE\", \"Annotators\", \"SCORE\"]\n",
    "metadata=pd.read_csv(r'C:\\Users\\Jay Kejriwal\\Desktop\\Jay\\StressDat\\StressDat-anotacia-29spk_v1_normalized.txt',sep=\"\\t\")\n",
    "conditions = [\n",
    "    (metadata['SCORE'] <= 20),\n",
    "    (metadata['SCORE'] > 20) & (metadata['SCORE'] <= 40),\n",
    "    (metadata['SCORE'] > 40)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['low', 'med', 'high']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "metadata['SCALE'] = np.select(conditions, values)\n",
    "# display updated DataFrame\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05585a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4=df3.rename(columns={'name':'FILE'})\n",
    "#df3=df2.rename(columns={\"name\": \"FILE\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#df=pd.read_csv(\"D:\\jaysfeaturesready.csv\",sep=\",\",encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced143f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ecfd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X1= pd.merge(metadata, df8, on='FILE', how='inner')\n",
    "X2= pd.merge(metadata, df9, on='FILE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b483752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>Annotators</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>SCALE</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s06h_10b_crisis_2_0315</td>\n",
       "      <td>2</td>\n",
       "      <td>28.846021</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[-6.885714, -0.036539752, -1.3000332, -12.0705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s01a_6b_crisis_2_0170</td>\n",
       "      <td>2</td>\n",
       "      <td>32.322045</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[-6.114928, -13.170886, 3.1732848, -16.58644, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s07n_8a_crisis_1_0244</td>\n",
       "      <td>1</td>\n",
       "      <td>17.074338</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[-0.11982711, -4.6934714, 3.7333794, -18.66026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s06h_9b_crisis_2_0284</td>\n",
       "      <td>2</td>\n",
       "      <td>43.659132</td>\n",
       "      <td>High</td>\n",
       "      <td>[-9.091105, -2.8438413, 2.1748102, -6.694515, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s03a_9a_crisis_1_0274</td>\n",
       "      <td>1</td>\n",
       "      <td>27.351947</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[-17.674513, -10.407426, -10.38577, -15.515516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12783</th>\n",
       "      <td>s29h_18a_crisis_1_0493</td>\n",
       "      <td>1</td>\n",
       "      <td>11.326830</td>\n",
       "      <td>Low</td>\n",
       "      <td>[-11.325671, 0.3797741, 1.0152626, -24.117195,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12784</th>\n",
       "      <td>s27h_19a_crisis_1_0537</td>\n",
       "      <td>1</td>\n",
       "      <td>5.753345</td>\n",
       "      <td>Low</td>\n",
       "      <td>[-14.158362, -0.39813623, 0.47560015, -2.58148...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>s26h_16b_crisis_2_0444</td>\n",
       "      <td>2</td>\n",
       "      <td>32.758280</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[2.4243116, -27.902876, 9.194534, -9.159864, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>s25h_19a_crisis_1_0526</td>\n",
       "      <td>1</td>\n",
       "      <td>5.866519</td>\n",
       "      <td>Low</td>\n",
       "      <td>[-16.77649, 4.831675, 10.54427, -0.12375169, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>s21h_16c_crisis_3_0472</td>\n",
       "      <td>3</td>\n",
       "      <td>50.199180</td>\n",
       "      <td>High</td>\n",
       "      <td>[-21.138865, -15.861292, -20.947367, -14.65717...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12788 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FILE  Annotators      SCORE   SCALE  \\\n",
       "0      s06h_10b_crisis_2_0315           2  28.846021  Medium   \n",
       "1       s01a_6b_crisis_2_0170           2  32.322045  Medium   \n",
       "2       s07n_8a_crisis_1_0244           1  17.074338  Medium   \n",
       "3       s06h_9b_crisis_2_0284           2  43.659132    High   \n",
       "4       s03a_9a_crisis_1_0274           1  27.351947  Medium   \n",
       "...                       ...         ...        ...     ...   \n",
       "12783  s29h_18a_crisis_1_0493           1  11.326830     Low   \n",
       "12784  s27h_19a_crisis_1_0537           1   5.753345     Low   \n",
       "12785  s26h_16b_crisis_2_0444           2  32.758280  Medium   \n",
       "12786  s25h_19a_crisis_1_0526           1   5.866519     Low   \n",
       "12787  s21h_16c_crisis_3_0472           3  50.199180    High   \n",
       "\n",
       "                                                features  \n",
       "0      [-6.885714, -0.036539752, -1.3000332, -12.0705...  \n",
       "1      [-6.114928, -13.170886, 3.1732848, -16.58644, ...  \n",
       "2      [-0.11982711, -4.6934714, 3.7333794, -18.66026...  \n",
       "3      [-9.091105, -2.8438413, 2.1748102, -6.694515, ...  \n",
       "4      [-17.674513, -10.407426, -10.38577, -15.515516...  \n",
       "...                                                  ...  \n",
       "12783  [-11.325671, 0.3797741, 1.0152626, -24.117195,...  \n",
       "12784  [-14.158362, -0.39813623, 0.47560015, -2.58148...  \n",
       "12785  [2.4243116, -27.902876, 9.194534, -9.159864, -...  \n",
       "12786  [-16.77649, 4.831675, 10.54427, -0.12375169, -...  \n",
       "12787  [-21.138865, -15.861292, -20.947367, -14.65717...  \n",
       "\n",
       "[12788 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5892a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>Annotators</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>SCALE</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s06h_10b_crisis_2_0315</td>\n",
       "      <td>2</td>\n",
       "      <td>28.846021</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[[-16.02819, -16.8747, -18.12041, -19.82817, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s01a_6b_crisis_2_0170</td>\n",
       "      <td>2</td>\n",
       "      <td>32.322045</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[[-13.09902, -8.843368, -14.96504, -12.98052, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s07n_8a_crisis_1_0244</td>\n",
       "      <td>1</td>\n",
       "      <td>17.074338</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[[-5.357763, -7.482312, -9.288478, -5.790257, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s06h_9b_crisis_2_0284</td>\n",
       "      <td>2</td>\n",
       "      <td>43.659132</td>\n",
       "      <td>High</td>\n",
       "      <td>[[-20.14553, -20.75005, -18.78026, -19.34788, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s03a_9a_crisis_1_0274</td>\n",
       "      <td>1</td>\n",
       "      <td>27.351947</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[[-18.3478, -26.09243, -31.76429, -28.83096, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12783</th>\n",
       "      <td>s29h_18a_crisis_1_0493</td>\n",
       "      <td>1</td>\n",
       "      <td>11.326830</td>\n",
       "      <td>Low</td>\n",
       "      <td>[[-20.48705, -22.83758, -29.1628, -29.91858, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12784</th>\n",
       "      <td>s27h_19a_crisis_1_0537</td>\n",
       "      <td>1</td>\n",
       "      <td>5.753345</td>\n",
       "      <td>Low</td>\n",
       "      <td>[[-19.12346, -21.15578, -17.01408, -19.01671, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>s26h_16b_crisis_2_0444</td>\n",
       "      <td>2</td>\n",
       "      <td>32.758280</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[[-14.77532, -20.431, -23.46951, -24.38121, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>s25h_19a_crisis_1_0526</td>\n",
       "      <td>1</td>\n",
       "      <td>5.866519</td>\n",
       "      <td>Low</td>\n",
       "      <td>[[-24.07748, -24.33992, -24.0927, -25.44589, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>s21h_16c_crisis_3_0472</td>\n",
       "      <td>3</td>\n",
       "      <td>50.199180</td>\n",
       "      <td>High</td>\n",
       "      <td>[[-25.72682, -32.3556, -23.17254, -0.7346775, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12788 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FILE  Annotators      SCORE   SCALE  \\\n",
       "0      s06h_10b_crisis_2_0315           2  28.846021  Medium   \n",
       "1       s01a_6b_crisis_2_0170           2  32.322045  Medium   \n",
       "2       s07n_8a_crisis_1_0244           1  17.074338  Medium   \n",
       "3       s06h_9b_crisis_2_0284           2  43.659132    High   \n",
       "4       s03a_9a_crisis_1_0274           1  27.351947  Medium   \n",
       "...                       ...         ...        ...     ...   \n",
       "12783  s29h_18a_crisis_1_0493           1  11.326830     Low   \n",
       "12784  s27h_19a_crisis_1_0537           1   5.753345     Low   \n",
       "12785  s26h_16b_crisis_2_0444           2  32.758280  Medium   \n",
       "12786  s25h_19a_crisis_1_0526           1   5.866519     Low   \n",
       "12787  s21h_16c_crisis_3_0472           3  50.199180    High   \n",
       "\n",
       "                                                features  \n",
       "0      [[-16.02819, -16.8747, -18.12041, -19.82817, -...  \n",
       "1      [[-13.09902, -8.843368, -14.96504, -12.98052, ...  \n",
       "2      [[-5.357763, -7.482312, -9.288478, -5.790257, ...  \n",
       "3      [[-20.14553, -20.75005, -18.78026, -19.34788, ...  \n",
       "4      [[-18.3478, -26.09243, -31.76429, -28.83096, -...  \n",
       "...                                                  ...  \n",
       "12783  [[-20.48705, -22.83758, -29.1628, -29.91858, -...  \n",
       "12784  [[-19.12346, -21.15578, -17.01408, -19.01671, ...  \n",
       "12785  [[-14.77532, -20.431, -23.46951, -24.38121, -1...  \n",
       "12786  [[-24.07748, -24.33992, -24.0927, -25.44589, -...  \n",
       "12787  [[-25.72682, -32.3556, -23.17254, -0.7346775, ...  \n",
       "\n",
       "[12788 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8121be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df = X1[[\"SCALE\",\"features\"]]\n",
    "extracted_features_df.columns=['class_label','feature']\n",
    "extracted_features_df.to_pickle(\"newmfcc_features3376_39features_1D.pkl\",protocol=4)\n",
    "extracted_features_df1 = X2[[\"SCALE\",\"features\"]]\n",
    "extracted_features_df1.columns=['class_label','feature']\n",
    "extracted_features_df1.to_pickle(\"newmfcc_features3376_39features_2D.pkl\",protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df['feature'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4efe42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#extracted_features_df = pd.read_pickle(\"newmfcc_features3376_13features_1D.pkl\")\n",
    "#extracted_features_df = pd.read_pickle(\"newmfcc_features3376_39features_1D.pkl\")\n",
    "#extracted_features_df = pd.read_pickle(\"newplp_features3376_13features_1D.pkl\")\n",
    "extracted_features_df = pd.read_pickle(\"newplp_features3376_39features_1D.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4299de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class_label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a342f70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789, 39)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2bf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8383eb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12789,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e77b9bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Medium', 'Medium', 'Medium', ..., 'Medium', 'Low', 'High'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e880aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=np.array(extracted_features_df['class_label'].tolist())\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5b57c263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:10]\n",
    "#yy[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "840fe77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ccdac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2bb1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "853e293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42e06112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(39,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49091d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c011903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f3351b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1.1429 - accuracy: 0.3509 - val_loss: 0.9913 - val_accuracy: 0.5258\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99134, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1.0013 - accuracy: 0.4858 - val_loss: 0.8664 - val_accuracy: 0.5766\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.99134 to 0.86644, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.9111 - accuracy: 0.5483 - val_loss: 0.8260 - val_accuracy: 0.5989\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.86644 to 0.82599, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.8720 - accuracy: 0.5708 - val_loss: 0.8038 - val_accuracy: 0.6286\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.82599 to 0.80375, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.8634 - accuracy: 0.5822 - val_loss: 0.7749 - val_accuracy: 0.6407\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.80375 to 0.77487, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.8327 - accuracy: 0.5995 - val_loss: 0.7593 - val_accuracy: 0.6403\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.77487 to 0.75932, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.8157 - accuracy: 0.6117 - val_loss: 0.7597 - val_accuracy: 0.6540\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.75932\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.8047 - accuracy: 0.6205 - val_loss: 0.7354 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.75932 to 0.73535, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7870 - accuracy: 0.6190 - val_loss: 0.7480 - val_accuracy: 0.6536\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.73535\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7814 - accuracy: 0.6238 - val_loss: 0.7191 - val_accuracy: 0.6830\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.73535 to 0.71909, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7720 - accuracy: 0.6399 - val_loss: 0.7182 - val_accuracy: 0.6837\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.71909 to 0.71816, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7640 - accuracy: 0.6426 - val_loss: 0.7186 - val_accuracy: 0.6873\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.71816\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7508 - accuracy: 0.6459 - val_loss: 0.6997 - val_accuracy: 0.6865\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.71816 to 0.69972, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7674 - accuracy: 0.6403 - val_loss: 0.6942 - val_accuracy: 0.7021\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.69972 to 0.69423, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7470 - accuracy: 0.6490 - val_loss: 0.7011 - val_accuracy: 0.6974\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.69423\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7393 - accuracy: 0.6576 - val_loss: 0.7087 - val_accuracy: 0.6908\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.69423\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7355 - accuracy: 0.6572 - val_loss: 0.6810 - val_accuracy: 0.7021\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.69423 to 0.68096, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7377 - accuracy: 0.6602 - val_loss: 0.6846 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.68096\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7282 - accuracy: 0.6597 - val_loss: 0.7182 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.68096\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7309 - accuracy: 0.6580 - val_loss: 0.7088 - val_accuracy: 0.6912\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.68096\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7135 - accuracy: 0.6804 - val_loss: 0.6838 - val_accuracy: 0.7045\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.68096\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7252 - accuracy: 0.6707 - val_loss: 0.6769 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.68096 to 0.67688, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7252 - accuracy: 0.6697 - val_loss: 0.7328 - val_accuracy: 0.6618\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.67688\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7376 - accuracy: 0.6522 - val_loss: 0.7057 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.67688\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7117 - accuracy: 0.6747 - val_loss: 0.6640 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.67688 to 0.66397, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7275 - accuracy: 0.6626 - val_loss: 0.6843 - val_accuracy: 0.7127\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.66397\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7215 - accuracy: 0.6704 - val_loss: 0.6796 - val_accuracy: 0.6951\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.66397\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7001 - accuracy: 0.6769 - val_loss: 0.6630 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.66397 to 0.66297, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7065 - accuracy: 0.6782 - val_loss: 0.6697 - val_accuracy: 0.7131\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.66297\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7031 - accuracy: 0.6738 - val_loss: 0.6545 - val_accuracy: 0.7209\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.66297 to 0.65448, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7099 - accuracy: 0.6738 - val_loss: 0.6852 - val_accuracy: 0.6982\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.65448\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7077 - accuracy: 0.6743 - val_loss: 0.6753 - val_accuracy: 0.7123\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.65448\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7164 - accuracy: 0.6732 - val_loss: 0.6735 - val_accuracy: 0.7021\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.65448\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7147 - accuracy: 0.6768 - val_loss: 0.7045 - val_accuracy: 0.6744\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.65448\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7071 - accuracy: 0.6745 - val_loss: 0.6942 - val_accuracy: 0.6919\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.65448\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7027 - accuracy: 0.6779 - val_loss: 0.6989 - val_accuracy: 0.6884\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.65448\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7030 - accuracy: 0.6692 - val_loss: 0.6575 - val_accuracy: 0.7217\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.65448\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7034 - accuracy: 0.6760 - val_loss: 0.6488 - val_accuracy: 0.7134\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.65448 to 0.64878, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6976 - accuracy: 0.6851 - val_loss: 0.6625 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.64878\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.6862 - val_loss: 0.6836 - val_accuracy: 0.6876\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.64878\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.6837 - val_loss: 0.6505 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.64878\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6829 - accuracy: 0.6849 - val_loss: 0.6573 - val_accuracy: 0.7177\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.64878\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6969 - accuracy: 0.6806 - val_loss: 0.6516 - val_accuracy: 0.7209\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.64878\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6980 - accuracy: 0.6842 - val_loss: 0.6488 - val_accuracy: 0.7205\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.64878\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7079 - accuracy: 0.6746 - val_loss: 0.6546 - val_accuracy: 0.7181\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.64878\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7032 - accuracy: 0.6772 - val_loss: 0.6471 - val_accuracy: 0.7127\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.64878 to 0.64707, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6827 - accuracy: 0.6840 - val_loss: 0.6515 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.64707\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6961 - accuracy: 0.6876 - val_loss: 0.6361 - val_accuracy: 0.7314\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.64707 to 0.63610, saving model to saved_models\\audio_classification3.hdf5\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.6812 - val_loss: 0.6663 - val_accuracy: 0.7170\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.63610\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6957 - accuracy: 0.6789 - val_loss: 0.6822 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.63610\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6698 - accuracy: 0.6940 - val_loss: 0.6629 - val_accuracy: 0.7099\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.63610\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6989 - accuracy: 0.6738 - val_loss: 0.6434 - val_accuracy: 0.7267\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.63610\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6708 - accuracy: 0.6876 - val_loss: 0.6668 - val_accuracy: 0.7119\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.63610\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6941 - accuracy: 0.6810 - val_loss: 0.6544 - val_accuracy: 0.7197\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.63610\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6962 - accuracy: 0.6832 - val_loss: 0.6567 - val_accuracy: 0.7213\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.63610\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.6802 - val_loss: 0.6521 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.63610\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.6786 - val_loss: 0.6554 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.63610\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.6927 - val_loss: 0.6530 - val_accuracy: 0.7119\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.63610\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6780 - accuracy: 0.6935 - val_loss: 0.6693 - val_accuracy: 0.7025\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.63610\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6723 - accuracy: 0.6926 - val_loss: 0.6632 - val_accuracy: 0.7232\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.63610\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6639 - accuracy: 0.6983 - val_loss: 0.6627 - val_accuracy: 0.7111\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.63610\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.6847 - val_loss: 0.6672 - val_accuracy: 0.6966\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.63610\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6808 - accuracy: 0.6933 - val_loss: 0.6516 - val_accuracy: 0.7174\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.63610\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.6859 - val_loss: 0.6422 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.63610\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6745 - accuracy: 0.6871 - val_loss: 0.6508 - val_accuracy: 0.7174\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.63610\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6958 - accuracy: 0.6860 - val_loss: 0.6467 - val_accuracy: 0.7271\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.63610\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.6887 - val_loss: 0.6550 - val_accuracy: 0.7236\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.63610\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6816 - accuracy: 0.6832 - val_loss: 0.6655 - val_accuracy: 0.7193\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.63610\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6791 - accuracy: 0.6858 - val_loss: 0.6454 - val_accuracy: 0.7154\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.63610\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.6888 - val_loss: 0.6637 - val_accuracy: 0.7185\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.63610\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6762 - accuracy: 0.6932 - val_loss: 0.6668 - val_accuracy: 0.7162\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.63610\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6790 - accuracy: 0.6917 - val_loss: 0.6505 - val_accuracy: 0.7232\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.63610\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6692 - accuracy: 0.6913 - val_loss: 0.6457 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.63610\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6811 - accuracy: 0.6948 - val_loss: 0.6442 - val_accuracy: 0.7217\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.63610\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6756 - accuracy: 0.6875 - val_loss: 0.6486 - val_accuracy: 0.7263\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.63610\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.6854 - val_loss: 0.6536 - val_accuracy: 0.7166\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.63610\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.6845 - val_loss: 0.6506 - val_accuracy: 0.7232\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.63610\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6686 - accuracy: 0.7010 - val_loss: 0.6497 - val_accuracy: 0.7310\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.63610\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.6842 - val_loss: 0.7077 - val_accuracy: 0.6904\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.63610\n",
      "Epoch 80/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.6900 - val_loss: 0.6740 - val_accuracy: 0.7013\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.63610\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.6883 - val_loss: 0.6529 - val_accuracy: 0.7213\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.63610\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.6804 - val_loss: 0.6559 - val_accuracy: 0.7244\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.63610\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6779 - accuracy: 0.6906 - val_loss: 0.6612 - val_accuracy: 0.7185\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.63610\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.6879 - val_loss: 0.6573 - val_accuracy: 0.7170\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.63610\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6698 - accuracy: 0.6952 - val_loss: 0.6554 - val_accuracy: 0.7189\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.63610\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6770 - accuracy: 0.6886 - val_loss: 0.6532 - val_accuracy: 0.7193\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.63610\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.6899 - val_loss: 0.6584 - val_accuracy: 0.7146\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.63610\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6728 - accuracy: 0.6917 - val_loss: 0.6502 - val_accuracy: 0.7201\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.63610\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6743 - accuracy: 0.6898 - val_loss: 0.6679 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.63610\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6708 - accuracy: 0.6936 - val_loss: 0.6572 - val_accuracy: 0.7154\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.63610\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6671 - accuracy: 0.6961 - val_loss: 0.6537 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.63610\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6688 - accuracy: 0.6948 - val_loss: 0.6723 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.63610\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6716 - accuracy: 0.6918 - val_loss: 0.6761 - val_accuracy: 0.7111\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.63610\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.6937 - val_loss: 0.6816 - val_accuracy: 0.7084\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.63610\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6667 - accuracy: 0.6973 - val_loss: 0.6506 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.63610\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6693 - accuracy: 0.6970 - val_loss: 0.6667 - val_accuracy: 0.7013\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.63610\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6654 - accuracy: 0.6999 - val_loss: 0.6729 - val_accuracy: 0.7064\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.63610\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6585 - accuracy: 0.6938 - val_loss: 0.6637 - val_accuracy: 0.7181\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.63610\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6664 - accuracy: 0.6975 - val_loss: 0.6749 - val_accuracy: 0.7064\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.63610\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6687 - accuracy: 0.6901 - val_loss: 0.6484 - val_accuracy: 0.7252\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.63610\n",
      "Training completed in time:  0:00:58.644423\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification3.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c8ebe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7217280864715576\n",
      "0.7251759171485901\n"
     ]
    }
   ],
   "source": [
    "train_accuracy=model.evaluate(X_train,y_train,verbose=0)\n",
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(train_accuracy[1])\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "291d23ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Test Data: Full Classification Report \n",
      "[[575  13 278]\n",
      " [  5 637 182]\n",
      " [ 73 167 628]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.66      0.76       866\n",
      "           1       0.78      0.77      0.78       824\n",
      "           2       0.58      0.72      0.64       868\n",
      "\n",
      "    accuracy                           0.72      2558\n",
      "   macro avg       0.75      0.72      0.73      2558\n",
      "weighted avg       0.75      0.72      0.72      2558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Kejriwal\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#For mfcc 13 features 1D\n",
    "##0.6095796823501587\n",
    "##0.5957779288291931\n",
    "\n",
    "#For plp 13 features 1D\n",
    "#0.7189912796020508\n",
    "#0.7193119525909424\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"For Test Data: Full Classification Report \")\n",
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f676b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Test Data: Full Classification Report \n",
      "[[600  15 251]\n",
      " [  6 648 170]\n",
      " [ 84 177 607]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77       866\n",
      "           1       0.77      0.79      0.78       824\n",
      "           2       0.59      0.70      0.64       868\n",
      "\n",
      "    accuracy                           0.73      2558\n",
      "   macro avg       0.74      0.73      0.73      2558\n",
      "weighted avg       0.74      0.73      0.73      2558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Kejriwal\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#For mfcc 39 features 1D\n",
    "#0.6368523836135864\n",
    "#0.623924970626831\n",
    "\n",
    "#For plp 39 features 1D\n",
    "#0.7217280864715576\n",
    "#0.7251759171485901\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"For Test Data: Full Classification Report \")\n",
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b79ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For normalized dataset\n",
    "#0.654180109500885\n",
    "#0.6531408429145813\n",
    "\n",
    "#For non-normalized score\n",
    "#0.6184763312339783\n",
    "#0.6115332245826721\n",
    "\n",
    "\n",
    "#For normalized dataset librosa settings\n",
    "#0.6336942911148071\n",
    "#0.6348029375076294\n",
    "\n",
    "#0.6662764549255371\n",
    "#0.6699180603027344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a68fbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import RandomSearch\n",
    "import keras_tuner\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4612fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "Y_train_ann_cnn = y_train\n",
    "Y_test_ann_cnn = y_test\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0392612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  \n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv1D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [2,5]),\n",
    "        activation='relu',\n",
    "        input_shape=X_train_cnn.shape[1:]\n",
    "    ),\n",
    "    keras.layers.Conv1D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [2,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=256, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f34767a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=5,directory='output',project_name=\"Stress_clasification_plp1D39\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7f5f121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 17s]\n",
      "val_accuracy: 0.6257938742637634\n",
      "\n",
      "Best val_accuracy So Far: 0.6888129115104675\n",
      "Total elapsed time: 00h 01m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(X_train_cnn, Y_train_ann_cnn, epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84269d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa4703f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 38, 80)            240       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 34, 32)            12832     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 144)               156816    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 435       \n",
      "=================================================================\n",
      "Total params: 170,323\n",
      "Trainable params: 170,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8aa9206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "256/256 [==============================] - 2s 5ms/step - loss: 0.6506 - accuracy: 0.7050 - val_loss: 0.7845 - val_accuracy: 0.6214\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6737 - accuracy: 0.6911 - val_loss: 0.6658 - val_accuracy: 0.6844\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6449 - accuracy: 0.7110 - val_loss: 0.6864 - val_accuracy: 0.6825\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6599 - accuracy: 0.6951 - val_loss: 0.6699 - val_accuracy: 0.6908\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6347 - accuracy: 0.7157 - val_loss: 0.9722 - val_accuracy: 0.5447\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6525 - accuracy: 0.7017 - val_loss: 0.6956 - val_accuracy: 0.6580\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6494 - accuracy: 0.7048 - val_loss: 0.6741 - val_accuracy: 0.6898\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6211 - accuracy: 0.7183 - val_loss: 0.7077 - val_accuracy: 0.6610\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6220 - accuracy: 0.7124 - val_loss: 0.6444 - val_accuracy: 0.7005\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6050 - accuracy: 0.7198 - val_loss: 0.6751 - val_accuracy: 0.6732\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6119 - accuracy: 0.7162 - val_loss: 0.6588 - val_accuracy: 0.6966\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.7127 - val_loss: 0.6460 - val_accuracy: 0.7054\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6247 - accuracy: 0.7097 - val_loss: 0.6556 - val_accuracy: 0.7113\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6206 - accuracy: 0.7159 - val_loss: 0.6557 - val_accuracy: 0.7035\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5988 - accuracy: 0.7289 - val_loss: 0.6495 - val_accuracy: 0.6952\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6092 - accuracy: 0.7269 - val_loss: 0.6576 - val_accuracy: 0.6981\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6083 - accuracy: 0.7310 - val_loss: 0.6642 - val_accuracy: 0.6942\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5806 - accuracy: 0.7311 - val_loss: 0.6424 - val_accuracy: 0.7035\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5870 - accuracy: 0.7335 - val_loss: 0.6810 - val_accuracy: 0.6790\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5841 - accuracy: 0.7313 - val_loss: 0.6277 - val_accuracy: 0.7035\n",
      "0.7430358529090881\n",
      "0.7259577512741089\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_cnn, Y_train_ann_cnn, epochs=30, validation_split=0.2, initial_epoch=10)\n",
    "train_accuracy=model.evaluate(X_train_cnn,Y_train_ann_cnn,verbose=0)\n",
    "test_accuracy=model.evaluate(X_test_cnn,Y_test_ann_cnn,verbose=0)\n",
    "print(train_accuracy[1])\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95c89490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Test Data: Full Classification Report \n",
      "[[710  14 142]\n",
      " [ 19 608 197]\n",
      " [208 159 501]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       866\n",
      "           1       0.78      0.74      0.76       824\n",
      "           2       0.60      0.58      0.59       868\n",
      "\n",
      "    accuracy                           0.71      2558\n",
      "   macro avg       0.71      0.71      0.71      2558\n",
      "weighted avg       0.71      0.71      0.71      2558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For mfcc 13 features 1D\n",
    "###0.8489736318588257\n",
    "###0.70719313621521\n",
    "#For plp 13 features 1D\n",
    "#0.7520281672477722\n",
    "#0.7111024260520935\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"For Test Data: Full Classification Report \")\n",
    "Y_test = np.argmax(Y_test_ann_cnn, axis=1) # Convert one-hot to index\n",
    "y_pred = np.argmax(model.predict(X_test_cnn),axis=-1)\n",
    "matrix=confusion_matrix(Y_test,y_pred)\n",
    "print(matrix)\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b2537f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[710  14 142]\n",
      " [ 19 608 197]\n",
      " [208 159 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-382279d99293>:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + labels)\n",
      "<ipython-input-31-382279d99293>:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + labels)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "labels=['High','Low','Medium']\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6a29f925",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-39583b3912c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclass_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextracted_features_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "class_label=extracted_features_df['class_label']\n",
    "plot_confusion_matrix(Y_test, y_pred, classes=class_label, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30cad557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Test Data: Full Classification Report \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Kejriwal\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[682  31 153]\n",
      " [ 13 668 143]\n",
      " [132 229 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81       866\n",
      "           1       0.72      0.81      0.76       824\n",
      "           2       0.63      0.58      0.61       868\n",
      "\n",
      "    accuracy                           0.73      2558\n",
      "   macro avg       0.73      0.73      0.73      2558\n",
      "weighted avg       0.73      0.73      0.72      2558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For mfcc 39 features 1D\n",
    "##0.8137829899787903\n",
    "##0.7126661539077759\n",
    "\n",
    "#For plp 39 features 1D\n",
    "##0.7430358529090881\n",
    "##0.7259577512741089\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"For Test Data: Full Classification Report \")\n",
    "Y_test = np.argmax(Y_test_ann_cnn, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_cnn)\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387583df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435e6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
